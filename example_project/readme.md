探索构建一个易读的通用训练框架
===
### 探索初衷
鄙人才疏学浅，现在很多主流模型的实现过于复杂，其对于调试和实验可能提供了极大的便捷，但对于初学者来说理解和修改起来相当不便。所以在这里想探索一种更加明确，更加易读的训练框架，在以易读为第一追求的目标下，尽可能增强其扩展性。该框架主要依据以下想法建立：<br>
1.减少不必要的可调整部分。这样在理解的时候可以不用陷在一些其实用不上的部分；<br>
2.分离模型和数据集。框架提供训练流程和一些常用的工具，而模型和数据集作为两个单独的可替换模块进行插入；<br>
3.对于父类和子类希望其不处在同一个文件中，方便调试的时候调用和修改。所以框架大约分为三层结构。在一个文件中不实现多个功能，utils除外。<br>
4.对于数据集，要求通过txt文件列表进行读取，<br>
5.对于GPU的应用，CUDA的转换在train中完成。若有新加的层则需自行建立

### 对训练的一些理解
训练一般由模型和损失函数作为主导，在`networks`中建立以`网络名称`用于存放模型主体，建立以`网络名称_layers`的文件或文件夹用于存放模型所需要的功能函数或层。<br>
注意，`network`中的网络应该仅仅包含：<br>
1.网络的初始化(init)，权重初始化（init_weight）,前向传播方式(forward)，转换模型类型（set_trian/set_eval）<br>
在`losses`文件夹中建立`loss.py`存放模型所需要的损失函数，建立`loss_utils`用来存放计算loss所需要的二级函数。

有了模型和损失函数，训练需要在一个数据集上进行，在`datasets`文件夹中建立`数据集名称_loader`用于存放所需要的数据集读取函数，建立`数据集名称_train`用来存放训练数据列表，建立`数据集名称_valid`用来存放验证数据列表。需要注意的是该列表中的文件应该都是相对路径，以适应工程的迁移使用。

设想一般的训练过程为：初始化记录器->载入网络模型->载入优化器->（载入模型参数）->构建dataloader->do_train（valid）->save-model->do_train（valid）->...

之后，需要构建训练过程，在`tool`文件夹中建立`train`用于存放训练的方法，同时在根目录建立`configs`用来存放可调整的参数。<br>
模型的载入。。。

推荐一种记录格式，以`时间`作为`log`文件下的第一层级，在里面分别存储`board_log`以及`models`方便之后查看或调用。<br>

在`tool`中建立`test`文件用于调用模型进行测试或作为最终使用的接口，其参数也放在'configs'中。在`output`文件加中保存输出的结果。<br>

### 具体例子
[分割网络]()

